{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ad3b1820-9be6-4780-9052-09ee6da24518"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import csv\n",
    "import copy\n",
    "import sklearn.linear_model\n",
    "import json\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "COLOR_TREAT = \"#2ecc71\"\n",
    "COLOR_NO_TREAT = \"#e74c3c\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_categorical(item, df=None, grouper='Active Status' , order = None , title = None , label = None , legend = None) :\n",
    "    # plot categorical responses to an item ('column name')\n",
    "    # by percent by group ('diff column name w categorical data')\n",
    "    # select a data frame (default is IA)\n",
    "    # 'Active Status' is default grouper\n",
    "\n",
    "    # create df of item grouped by status\n",
    "    grouped = (df.groupby(grouper)[item]\n",
    "    # convert to percentage by group rather than total count\n",
    "                .value_counts(normalize=True)\n",
    "                # rename column \n",
    "                .rename('percentage')\n",
    "                # multiple by 100 for easier interpretation\n",
    "                .mul(100)\n",
    "                # change order from value to name\n",
    "                .reset_index()\n",
    "                .sort_values(item))\n",
    "\n",
    "    # create plot\n",
    "    \n",
    "    f, axarr = plt.subplots(1, 2, figsize = (15,8))\n",
    "    \n",
    "    sns.barplot(x=item,\n",
    "                         y='percentage',\n",
    "                         hue=grouper,\n",
    "                         data=grouped,\n",
    "                         palette='RdBu' , order = order , ax = axarr[0]\n",
    "                         )\n",
    "    \n",
    "    \n",
    "    \n",
    "    sns.countplot( x = item , data= df , hue = grouper , palette='RdBu' , order = order , ax = axarr[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if title == None:\n",
    "        title = ['' , '']\n",
    "    \n",
    "    axarr[0].set_title(title[0] , size =15)\n",
    "    axarr[1].set_title(title[1] , size =15)\n",
    "    if label == None :\n",
    "        label = item\n",
    "    axarr[0].set_xlabel(label , size = 15)\n",
    "    axarr[1].set_xlabel(label , size =15)\n",
    "    \n",
    "    axarr[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "    axarr[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "    \n",
    "    axarr[0].set_xticklabels(order , rotation=45 )\n",
    "    axarr[1].set_xticklabels(order , rotation=45 )\n",
    "    \n",
    "    axarr[0].set_ylabel('Percent' , size = 15)\n",
    "    axarr[1].set_ylabel('Counts',  size =15 )\n",
    "    \n",
    "    if legend != None:\n",
    "        \n",
    "        for ax in axarr :\n",
    "            leg_handles = ax.get_legend_handles_labels()[0]\n",
    "            ax.legend(leg_handles, [legend[1], legend[2]], title=legend[0])\n",
    "            plt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "            plt.setp(ax.get_legend().get_title(), fontsize='15')\n",
    "    \n",
    "    return axarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "478042d3-2861-44e0-af17-88a47fb07b2e"
    }
   },
   "source": [
    "# Data exploration of conflicts and agreements\n",
    "## Naïve analysis of the peace agreement dataset :\n",
    "\n",
    "The Peace agreements dataset contains a large set of variable (69) defining the type of the agreement signed. We list below a few explanations of the features.\n",
    "\n",
    "** PAID : ** Peace Agreement ID\n",
    "\n",
    "**Region : **\n",
    "The regional variable specifies the regional location of the conflict:\n",
    "1. Europe: Geographic definition, including the states in the Caucasus. (COW numbers 200–395) \n",
    "2. Middle East: Egypt, Iran, Iraq, Israel, Jordan, Kuwait, Lebanon, Syria, Turkey, and the states of the Arabian Peninsula (COW numbers 630–698)\n",
    "3. Asia: Geographic definition, including Oceania, Australia, and New Zealand, and excluding states in the Middle East. (COW numbers 700–990)\n",
    "4. Africa: Geographic definition, excluding states in the Middle East (eg. Egypt). (COW numbers 400– 625)\n",
    "5. Americas: Geographic definition, including states in the Caribbean. (COW numbers 2–165)\n",
    "\n",
    "**GWNO : ** Gleditsch & Ward System Membership Table, it represents the country code\n",
    "\n",
    "**CID : ** - Conflict ID\n",
    "\n",
    "** Ended : ** 1 represents a PA that was terminated, 0 its success.\n",
    "\n",
    "This dataset contains also some binary features to define the type of the agreement. There are binary features for :\n",
    "- Behavioral conduct of the warring parties\n",
    "- Regulation of governmental incompatibility\n",
    "- Regulation of territorial incompatibility\n",
    "- Justice issues\n",
    "- Implementation issues\n",
    "- Termination Variables : which corresponds to the evaluation of the agreement\n",
    "- Type of process : is a full or partial peace agreement process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4f97cb14-df7a-40e6-bcd0-36b12d2572e5"
    }
   },
   "outputs": [],
   "source": [
    "pa = pd.read_excel('data/ucdp-peace-agreements.xls')\n",
    "cols = ['bwdID', 'pa_comment', 'c_sign', 'c_3rd', 'c_duration', 'Reaffirm ID', 'Comment', 'txt', \n",
    "        'Link to fulltext agreement', 'ProcID', 'Frame', 'All', 'Counter' , 'Duration']\n",
    "pa.drop(columns=cols, inplace=True)\n",
    "regiondic = {\n",
    "    1:'Europe',\n",
    "    2:'Middle East',\n",
    "    3:'Asia',\n",
    "    4:'Africa',\n",
    "    5:'Americas'\n",
    "}\n",
    "pa['Region'].replace(regiondic , inplace = True)\n",
    "\n",
    "searchfor = ['UN', 'United Nations' , 'united nations' , 'ONU']\n",
    "pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('|'.join(searchfor))]\n",
    "inter = list(set(pa_UN.PAID).intersection(pa.PAID))\n",
    "pa[\"UN\"] = ['UN intervention' if ele in inter else 'No UN intervention' for ele in pa.PAID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9ea89e59-0b2b-4ec4-857a-191751d91f20"
    }
   },
   "source": [
    "## Distribution of the agreements by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7cbd57cb-a637-4b4a-be7c-1a4cb1a7d251"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Region', data=pa, color=COLOR_TREAT, order=pa.Region.value_counts().index)\n",
    "plt.title('Agreement counts per region')\n",
    "plt.xlabel('Region');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "19d3e0ca-1479-40cf-9c9c-d52cae65f81e"
    }
   },
   "source": [
    "This plot shows the number of peace agreements per region. We can see that most agreements concern African conflicts. It should be noted that this plot sums the number of Peace agreements per region. There are more peace agreements signed in the african region but the percentage of conflicts that are treated by Peace agreements differs a lot.\n",
    "\n",
    "## Distribution of agreements by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7312b54d-08b8-418d-8ec8-6790b185cecf"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x='Year', data=pa, color=COLOR_TREAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5));\n",
    "sns.countplot(x='Year', data=pa, hue='UN', palette='RdBu');\n",
    "plt.title('Number of the Peace Agreements by year', Fontsize=18)\n",
    "plt.legend( ['Without' , 'With'] ,fontsize = 'large' , title = 'UN intervention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year distibution of Peace agreements\n",
    "1991 is the year where most peace agreements were signed. There has been two periods with a low amount of peace agreement, from 1983 to 1987 and from 2009 to 2011. Until 1990, The UN were not taking part to Peace agreements except for the Peace Process agreement between Namibia and South Africa in 1978."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.factorplot(kind='count', x='Inc', hue='UN', col='ended', size=6, data=pa, palette='RdBu');\n",
    "plt.xlabel('Conflict incompatibility', fontsize=18)\n",
    "ax.axes.flat[0].set_xlabel('Conflict incompatibility', fontsize=18)\n",
    "ax.axes.flat[0].set_ylabel('Number of PAs', fontsize=18)\n",
    "ax.axes.flat[0].set_title('Teminated PAs per conflict incompatibility', fontsize=17)\n",
    "ax.axes.flat[1].set_title('Successful PAs per conflict incompatibility', fontsize=17)\n",
    "plt.savefig('frontend/img/images/PA_Inc.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_categorical('pa_type' , df=pa , grouper = 'UN' , order = pa.pa_type.value_counts().index,\n",
    "                   title = ['Distribution of the PAs by type' , 'Number of PAs of each type'],\n",
    "                   label = 'Type of agreement' , \n",
    "                   legend = ['UN intervention' , 'without' , 'with']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive strength of peace agreements\n",
    "Most peace agreements are partial peace agreements. Peace Process agreements are generally agreements that are signed at the begginning of a conflict and call for future peace agreements. This figure that UN involvment in the peace agreements does not change much the distribution of the the PAs types.\n",
    "\n",
    "## UN involvment in the Peace agrements\n",
    "First create a new dataset with only the agreements where the UN took part then, create a new column in the pa dataset (1 if the agreement was signed by the UN, else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchfor = ['UN', 'United Nations' , 'united nations' , 'ONU']\n",
    "#pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('UN')]\n",
    "pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('|'.join(searchfor))]\n",
    "inter = list(set(pa_UN.PAID).intersection(pa.PAID))\n",
    "pa[\"UN\"] = [1 if ele in inter else 0 for ele in pa.PAID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check how many conflicts did the UN solved\n",
    "pa.groupby(\"UN\").PAID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_be_categorical = ['termdur' , 'noconf11' , 'CoVi01' ,'DyVi05' ]\n",
    "for categ in to_be_categorical:\n",
    "    pa[categ] = pd.Categorical(pa[categ] , pa[categ].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='CID', data= pa_UN, hue='ended', order=pa_UN.CID.value_counts().index, palette='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 216 agreements, The United Nations were involved as a third party in 68 of them which means 31%. We detect three groups of conflicts out of 35 concerned. 10 conflicts were not solved with the agreements, 3 conflicts were solved in three agrements with the one or two agreements that terminated. 11 conflicts had all of their respective agreements still valid as of 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "01e7dc8b-d1e0-4b22-946c-cb0d294a2ff7"
    }
   },
   "source": [
    "\n",
    "## Analysis of the Conflict ID variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "4ac065aa-aadb-4fbe-9f68-2b736acd41b5"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of conflicts treated in this dataset : %s' %(len(pa.CID.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3fcde142-5229-4f47-9cad-92e67b80c775"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='CID', data=pa, order=pa.CID.value_counts().index, color=COLOR_TREAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e9592e72-a0fe-43b1-ad95-d93d4fab4acc"
    }
   },
   "source": [
    "This plot shows that approximtely half of the conflicts were treated with one agreement. We wil split the rest of the exploration into two groups, the ones solved in one agreements and one grouping all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='CID', data= pa, hue='ended', order=pa.CID.value_counts().index, palette='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most conflicts ended with agreements that are still valid today. \n",
    "All agreements of the conflicts (179, 128, 177, 101, 216 205, 185) were terminated which means that none of them worked. \n",
    "\n",
    "\n",
    "## Analysis of the conflicts that could not be ended by the peace agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_128 = pa.loc[pa['CID'] == 128]\n",
    "#pa_128.to_csv('Unsolved_CID128.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2271560b-a476-4a18-8f6c-1e5feecde342"
    }
   },
   "source": [
    "**Conflict 128 :**\n",
    "\n",
    "Conflict between Iran and Iraq. Each of the 12 agreements were signed in 1975. Despite the first agreements, that was signed by The Shah of Iran and Saddam Hussein, all of them were signed by the same two representatives of Iran and Iraq, respectively by ABBAS-ALI KHALATBARY, Minister for Foreign Affairs of Iran and SAADOUN HAMADI, Minister for Foreign Affairs of Iraq. \n",
    "These agreements that were active in 1975, were than terminated between 1975 and 1980 until they were reactivated. Although the agreements were reactivated in 1980. Conflicts between Iran and Iraq did not stop in 1980, hence we can consider those agrrements as failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_179 = pa.loc[pa['CID'] == 179]\n",
    "#pa_179.to_csv('Unsolved_CID179.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conflict 179 :**\n",
    "\n",
    "This conflict concerned the Government of the Republic of Rwanda and the Rwandese Patriotic Front. The six agreements were signed between 1992 and 1993. The incompatibility is governmental.\n",
    "The five first agreements were signed to provide partial peace and the last one in august 1993 was supposed to prvide full peace to the region. None of the agreements provided for the holding of national talks to solve incompatibility and for the integration of rebels into civil service.\n",
    "In April 1994, a genocide broke out and the peace agreements were never fully implemented.\n",
    "\n",
    "**Conflict 101 : **\n",
    "\n",
    "This conflict originated from a governmental incompatibility between South Africa and Namibia. The agreement was signed in 1978 and lasted two months. The agreement contained provisions for political incompatibilities leading to independence for Namibia, justice provisions with the return of refugees and release of political prisoners and behavior regulations such as (ceasefire, withdrawal of foreign forces and demobilisation of local armies).\n",
    " \n",
    "**Conflict 216 : **\n",
    "\n",
    "Government of Guinea Bissau - Military Junta for the Consolidation of Democracy, Peace and Justice. Incompatibility 2, The peace agreement lasted for 6 months.\n",
    "\n",
    "** Conflict 205 : **\n",
    "\n",
    "The agreement covered indigenous rights and culture and strengthened the position of the indigenous people in Mexico. incompatibility 2. The accord was never implemented and thus further peace talks that were planned in September the same year were suspended by EZLN. No exact date for the ending of the peace accord has been found.\n",
    "\n",
    "All of the conflicts that were treated by only one agreement and had terminated originated from governmental imcompabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze conflicts solved in one agreements that are still valid as of 2011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pa['CID'].value_counts()\n",
    "idx_1 = idx[idx.values == 1]\n",
    "idx_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_1_ended = []\n",
    "for ind in idx_1.index:\n",
    "    #print(ind)\n",
    "    a = pa.ended[pa['CID'] == ind]\n",
    "    if a.iloc[0] == 0: # ended is the column 17 \n",
    "        indx_1_ended.append(a.index)\n",
    "    \n",
    "pa_one = pa.iloc[np.array(indx_1_ended)[:,0], :]\n",
    "pa_one.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's analyse the different combination of behavioral provisions that were taken and led to the success of the these agreements.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 5\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)\n",
    "pa_1behavior = pa_one.iloc[:, 20:25]\n",
    "pa_1behavior['combination'] = pa_1behavior.apply(whatcombi, axis=1)\n",
    "sns.countplot(x='combination', data=pa_1behavior, order=pa_1behavior.combination.value_counts().index, color=COLOR_TREAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 successfull agreements established peace in providing for a ceasefire. 3 provided for the withdrawal of foreign forces and 3 others provided for a ceasefire, the integration of rebels into the army and the disarmement of the warring parties.\n",
    "\n",
    "**Let's analyse the different combination of governmental and territorial incompatibility provisions that were taken and led to the success of the these agreements.**\n",
    "\n",
    "Because we merged the incompabilities, the number of possible combinations to analyse equals to $2^{18}$ hence we saved the results to save computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 18\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)\n",
    "#pa_1incompatibility = pa.iloc[:, 25:43]\n",
    "#pa_1incompatibility['combination'] = pa_1incompatibility.apply(whatcombi, axis=1)\n",
    "#pa_1incompatibility.to_csv('pa_1PA_success.csv')\n",
    "pa_1incompatibility = pd.read_csv('data/pa_1PA_success.csv')\n",
    "#pa_1incompatibility['inc'] = pa.iloc[np.array(indx_1_ended)[:,0], 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = copy.deepcopy(pa_1incompatibility.groupby('combination').count().pp)\n",
    "a.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "a[:20].plot('bar', rot=45, color=COLOR_TREAT)\n",
    "#sns.countplot(x='combination', data=pa_1incompatibility, order=pa_1incompatibility.combination.value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, no incompatibility provisions is set in those successful agreements. The abscence of incompatibility provisions might be an insight to explain their success as they do not have high expectations. The second most recurrent agreements treat territorial incompatibilities and grant the disputed region local governance. Governmental incompatibilities are mostly solved with provisions for elections and an interim government."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whatcombi :  This function returns corresponding combination to a pandas row dataframe\n",
    "This function is to be used for each type of provisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "546f25d4-9b24-400c-b33e-a5eed26979d5"
    }
   },
   "outputs": [],
   "source": [
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 2\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "eb06f137-5768-4e99-b6d2-0704de6e9d5a"
    }
   },
   "source": [
    "## Analysis of the agreements termination consistency in the variables :\n",
    "\n",
    "- **ended** \n",
    "    - 0) if the agreements still holds\n",
    "    - 1) if the agreement terminated\n",
    "    \n",
    "- **DyVi05** \n",
    "    - 1) the dyad violence restarted or continued\n",
    "    - 0) the violence ended in this dyad\n",
    "    - -99) Not applicable, agreement signed previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "34ca824b-390e-45bd-b56c-da29549e86fd"
    }
   },
   "outputs": [],
   "source": [
    "pa_result = pa.loc[:, ['ended', 'DyVi05']]\n",
    "pa_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a609534e-d9d2-4788-9bfb-eeb7fd489ea7"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "sns.countplot(x='DyVi05', data=pa, color=COLOR_TREAT)\n",
    "plt.subplot(122)\n",
    "sns.countplot(x='ended', data=pa, color=COLOR_TREAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0b9bf39e-38db-44ee-91f5-d24fd6f1161c"
    }
   },
   "source": [
    "Thoses plots show that approximately 140 agreements ended there corresponding conflict. This information should be crossed with the number of conflicts treated in this dataset as there are only 60 unique conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "47aebee3-7795-43a4-b1ca-ce349b7cd012"
    }
   },
   "outputs": [],
   "source": [
    "pa_result['combination'] = pa_result.apply(whatcombi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "81722778-b328-4191-833a-9ba37901f5e4"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='combination', data=pa_result, color=COLOR_TREAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b3e36695-1655-4f3b-8cb1-8c8bafe717a7"
    }
   },
   "source": [
    "Approximately 160 out of 216 (74%) agreements have the same values for the *ended* and *DyVi05* variables. Hence we can say that those variables are consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3589384a-d843-4479-a80c-1a3d25a606e2"
    }
   },
   "source": [
    "## Behaviour variables analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2f1f583d-dd26-4b41-9cc4-c95b1a053a38"
    }
   },
   "outputs": [],
   "source": [
    "pa_behavior = pa.iloc[:, 14:18]\n",
    "pa_behavior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6b24d465-d578-4246-b1dd-297c1ce7e3e2"
    }
   },
   "outputs": [],
   "source": [
    "# run only once\n",
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 4\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)\n",
    "pa_behavior['combination'] = pa_behavior.apply(whatcombi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "354fef1a-18ec-4abf-af42-42b542490ba5"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='combination', data=pa_behavior, order=pa_behavior.combination.value_counts().index, \n",
    "              color=COLOR_TREAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1f64186e-0ba8-4b5d-8edb-8f6655d4ab45"
    }
   },
   "source": [
    "1. Most agreements do not treat behavioral instructions\n",
    "2. The second most recurrent combination concerns agreements that provided a ceasefire\n",
    "3. third most recurrent :  ceasefire, Disarmement of foreign forces\n",
    "4. fourth : ceasefire, integration in national army, disarmement of warring parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "0ef6d2c1-ac9f-4db3-9f07-543ffb334166"
    }
   },
   "outputs": [],
   "source": [
    "pa_behavior['ended'] = pa['ended']\n",
    "pa_behavior['UN'] = pa['UN']\n",
    "sns.factorplot(x='combination', data= pa_behavior, hue='ended', col='UN', kind='count', size=6, aspect = 1.2, \n",
    "               palette='RdBu', order=pa_behavior.combination.value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8010e71f-79fd-45af-9691-8a87873781fd"
    }
   },
   "source": [
    "There are no much difference in agreements that terminate or not. However Two kinds of agreements were never terminated. The ones which provided for the creation of a new national army or the integration of rebels into the army and the withdrawal of foreign forces. No much difference can be established between UN agreements and the others considering the small amount of data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7dbf1538-f8d8-40df-9eee-55733f7c0ea7"
    }
   },
   "source": [
    "## Incompatibility variables analysis\n",
    "### Government incompatibilities\n",
    "Run the whatcombi box for n = 7 which leads to $2^7$ possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f5a970fe-a929-4a78-84bf-091cb0777ca1"
    }
   },
   "outputs": [],
   "source": [
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 7\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)\n",
    "pa_incompatibility_gov = pa.iloc[:, 19:26]\n",
    "pa_incompatibility_gov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "153420d9-04d8-4062-a0a9-5a687daa8e52"
    }
   },
   "outputs": [],
   "source": [
    "pa_incompatibility_gov['combination'] = pa_incompatibility_gov.apply(whatcombi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7836ff45-2929-48ba-ba2c-d4d808601467"
    }
   },
   "outputs": [],
   "source": [
    "pa_incompatibility_gov['UN'] = pa[\"UN\"]\n",
    "pa_incompatibility_gov['ended'] = pa['ended']\n",
    "sns.factorplot(x='combination', data=pa_incompatibility_gov, hue='ended', col='UN', kind='count', size=6, aspect = 1.2,\n",
    "              palette='RdBu', order=pa_incompatibility_gov.combination.value_counts().index)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d5cf6ca2-e50f-4540-8c2e-9a728655f1d2"
    }
   },
   "source": [
    "While most agreements do not deal with governmental incompatibilities, the ones that do mostly provide for elections and electoral reforms for rebel integration into the interim government.\n",
    "\n",
    "The main difference that can be observed between UN agreements and non UN agreements is that the UN agreements usually provide provisions for an interim government and elections while non UN agreements msotly only provide provisions for an election.\n",
    "\n",
    "The *Pol_prov* feature could be used to generalize the inclusion of political provisions in the agreement\n",
    "\n",
    "### Territorial incompatibilities\n",
    "run whatcombi box with n = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 9\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)\n",
    "pa_incompatibility_ter = pa.iloc[:, 27:36]\n",
    "pa_incompatibility_ter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_incompatibility_ter['combination'] = pa_incompatibility_ter.apply(whatcombi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_incompatibility_ter['UN'] = pa[\"UN\"]\n",
    "pa_incompatibility_ter['ended'] = pa['ended']\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.countplot(x='combination', data=pa_incompatibility_ter, hue='ended',\n",
    "             palette='RdBu', order=pa_incompatibility_ter.combination.value_counts().index)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant difference between UN agreements and the rest to display it. However we can see with this plot that when agreements have territorial provisions, it generally concerns the demarcation of a border or the government granting the disputed region to the other warring party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ee0d5d12-f4c2-4f46-a02d-9c0ff6b847a2"
    }
   },
   "source": [
    "## Justice variables analysis\n",
    "Run whatcombi box with n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b3abe992-672f-43a3-9d31-0d85ff4fb8d6"
    }
   },
   "outputs": [],
   "source": [
    "def whatcombi(pa):\n",
    "    # returns the corresponding combination number of the dataset\n",
    "    # set : n and rerun box in fct of the number of binary features to be analyzed\n",
    "    n = 4\n",
    "    # Create 2^n vectors of size n representing a combination\n",
    "    lst = [list(i) for i in itertools.product([0, 1], repeat=n)]\n",
    "    for i in range(len(lst)):\n",
    "        a = pa == lst[i]\n",
    "        # if all values in a are true, it is the good combination\n",
    "        if all(x for x in a.values):\n",
    "            return(i)\n",
    "pa_justice = pa.iloc[:, 37:41]\n",
    "pa_justice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "29165db6-e23d-40a3-ad63-d7e9d01eb9cd"
    }
   },
   "outputs": [],
   "source": [
    "# run only once\n",
    "pa_justice['combination'] = pa_justice.apply(whatcombi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a5a0847f-61b8-4ccc-8fe4-18a78d34c798"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='combination', data=pa_justice, color=COLOR_TREAT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_justice['UN'] = pa[\"UN\"]\n",
    "pa_justice['ended'] = pa['ended']\n",
    "sns.factorplot(x='combination', data=pa_justice, hue='ended', col='UN', kind='count', size=6, aspect = 1.2,\n",
    "              palette='RdBu', order=pa_justice.combination.value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "081a0db9-05e7-411f-ac27-70cbc9821c03"
    }
   },
   "source": [
    "- The most recurring combination is the one where no justice issues is treated in the agreement.\n",
    "- The second most recurring is the one where the agreement provided a release of prisoners\n",
    "\n",
    "It seems like UN agreements uses a smaller amount of combinations than other agreements, particularly, the combination 13 corresponding to an amnesty, a release of prisoners and the return of refugees. Again this interpretation has to be understood with modesty as we lack data to be more consistent. A less naïve analysis will be made later to solve this issue.\n",
    "\n",
    "The *Justice_prov* feature is set to one if any of the justice provisions was applied in the agreement. This variable could be of good use to reduce the number of features and keep an insight of the rather or not 'Justice' issues treated in the agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dae3c63c-d1bc-424a-9061-f37e50af92d9"
    }
   },
   "source": [
    "## Implementation variables analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "466e3eb7-1932-472e-a374-33083a5d94a9"
    }
   },
   "outputs": [],
   "source": [
    "pa_implementation = pa.iloc[:, 42:46]\n",
    "# study ended results in fct of all combinations of the binary features\n",
    "pa_implementation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a9f692d0-f587-4c4a-beec-4290320cc96d"
    }
   },
   "outputs": [],
   "source": [
    "# run only once\n",
    "pa_implementation['combination'] = pa_implementation.apply(whatcombi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e1d2eda1-e4e8-4847-b240-474a84c7a143"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='combination', data=pa_implementation, color=COLOR_TREAT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_implementation['UN'] = pa[\"UN\"]\n",
    "pa_implementation['ended'] = pa['ended']\n",
    "sns.factorplot(x='combination', data=pa_implementation, hue='ended', col='UN', kind='count', size=6, aspect = 1.2,\n",
    "              palette='RdBu', order=pa_implementation.combination.value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c57f1295-e2cc-48aa-bb3f-c3c6c2928542"
    }
   },
   "source": [
    "- The most recurring implementation is the one where the agreement did not reaffirm earlier agreements, did not outline a negotiating agenda including negotiations on the incompatibility, did not provide for the deployment of a peace-keeping operation and did not provide for the establishment of a commission or committee to oversee implementation of the agreement.\n",
    "\n",
    "- The second most combination recurring only provided for the establishment of a commission or committee to oversee implementation of the agreement.\n",
    "\n",
    "- The third most recurring combination outline a negotiating agenda including negotiations on the incompatibility\n",
    "\n",
    "- Fourth : reaffirm earlier agreements and provided the establishment of a commission or committee to oversee implementation of the agreement.\n",
    "\n",
    "A small diference between the agreements where the UN was involved and those where it wasn't are the ones where a provision for peace keeping operations is made. This is of course logical because the UN is the entity that generally decides for such missions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "806e31eb-691e-4832-a82f-4d1a5c61255b"
    }
   },
   "source": [
    "## Temination variables\n",
    "- **DyVi05** - Violence with the same parties restarted within 5 years\n",
    "\n",
    "    - 1) Yes, the dyad violence restarted or continued\n",
    "    - 0) No, the violence ended in this dyad\n",
    "    - -99) Not applicable, agreement signed previous year\n",
    "\n",
    "\n",
    "- **CoVi01** - Terminated the whole conflict the following year, signed an active year\n",
    "    - 2) Part of a peace process which ended the violence.\n",
    "    - 1) Yes, the conflict was terminated\n",
    "    - 0) No, the conflict continued\n",
    "    - -99) Not applicable, for example, the peace agreement was not signed in a conflict active year.\n",
    "\n",
    "\n",
    "- **noconf** - Signed in a conflict inactive year.\n",
    "\n",
    "The peace agreement was signed in an inactive conflict year i.e. in a year with less than 25 battle- related deaths recorded by the UCDP.\n",
    "    - 1) Yes \n",
    "    - 0) No\n",
    "\n",
    "- **termdur** - Number of years since last activity.\n",
    "\n",
    "The number of inactive years between end of conflict and signature of the peace agreement.\n",
    "\n",
    "\n",
    "- **Noconf11** - Still terminated as of 2011\n",
    "    No active conflict years recorded from agreement until 2011 1) Yes, no active conflict years from agreement til 2011, \n",
    "    - 0) No, conflict restarted before 2011\n",
    "    - -99) Not applicable, signed in 2011\n",
    "    \n",
    "The *termdur* will be used to relate agreement signed on active years to ones signed on inactive year. This should allow us to give more strentgh to an agreement that was signed fewer years after the end of the conflict than one signed a long time after. \n",
    "\n",
    "The *DyVi05* feature will be used as the second success evaluation variable. The *CoVi01* feature will be used to evaluate the time efficiency of the agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check propensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's reimport the data as we used it a lot in the previous analysis, we want it to be clean\n",
    "pa = pd.read_excel('data/ucdp-peace-agreements.xls')\n",
    "cols = ['bwdID', 'pa_comment', 'c_sign', 'c_3rd', 'c_duration', 'Reaffirm ID', 'Comment', 'txt', \n",
    "        'Link to fulltext agreement', 'ProcID', 'Frame', 'All', 'Counter' , 'Duration']\n",
    "pa.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some further cleaning\n",
    "#pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('UN')]\n",
    "#pa[\"UN\"] = [1 if ele in pa_UN.CID else 0 for ele in pa.CID]\n",
    "\n",
    "searchfor = ['UN', 'United Nations' , 'united nations' , 'ONU']\n",
    "pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('|'.join(searchfor))]\n",
    "inter = list(set(pa_UN.PAID).intersection(pa.PAID))\n",
    "pa[\"UN\"] = [1 if ele in inter else 0 for ele in pa.PAID]\n",
    "pa[pa['UN'] == 1]\n",
    "\n",
    "\n",
    "\n",
    "to_be_categorical = ['termdur' , 'noconf11' , 'CoVi01' ,'DyVi05' ]\n",
    "for categ in to_be_categorical:\n",
    "    pa[categ] = pd.Categorical(pa[categ] , pa[categ].unique())\n",
    "pa.groupby('UN').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.iloc[:, 13:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "#removing the useless features\n",
    "pa_reg = pa.iloc[:, 13:-2]\n",
    "\n",
    "#prepocess by standardizing the dataset\n",
    "pa_reg = preprocessing.scale(pa_reg)\n",
    "#Perform a logistic regression in order to get the propensity score for each individuals\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(pa_reg, pa.UN)\n",
    "pred = model.predict_proba(pa_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check the performance of our model, we have an accuracy of 89% which is quite good for a very simple logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the performance of the model\n",
    "sum(model.predict(pa_reg) == pa.UN)/len(pa_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot of the propensity score\n",
    "plt.figure(figsize=(15, 10))\n",
    "pa['pred'] = pred[:,1]\n",
    "ax = sns.stripplot(x='PAID', y='pred', hue='UN', data=pa, palette={0:\"#e74c3c\", 1: \"#2ecc71\"})\n",
    "ax.set(xticklabels=[], ylabel='Treatment (prediction)')\n",
    "plt.title('Propensity score per agreement')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., handles=ax.get_legend_handles_labels()[0], labels=['Without', 'With'], title='UN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows us what the propensity score for each PAID is. The UN PAID are in green and should have a score around 1 whereas the PAID without the UN are in red and should have a score around 0. Even if we have some outliers, this is what we observe on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that every PAID has a pred value\n",
    "pa.pred.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the matching.\n",
    "\n",
    "We saw in class that matching among the propensity score is almost the same as matching among the features.\n",
    "\n",
    "In order to do this matching, we will procede in the following way:\n",
    "\n",
    "\n",
    "- First, we will create a complete bipartite graph. It means that the vertices are partitioned into two subsets V1 (the people who received the training) and V2 (the people who did not receive the traing) such that no edge has both endpoints in the same subset, and every possible edge that could connect vertices in different subsets is part of the graph. This way will will be sure to match UN PAID people with PAID without the UN\n",
    "\n",
    "- We will give a weight to these edges: Let's take two PAID,we denote by $w_1$ the propensity score of the UN PAID and $w_2$ the propensity score of the other PAID (no UN). The weight of the edge between them will be:\n",
    "$$W = - |w_{1} - w_{2}| $$\n",
    "\n",
    "- Finally we will use a maximum weight matching with max cardinality algorithm. Note that we have a minus sign in our weights because we want to minimize the weights even though we are using a maximum weight matching algorithm. We are using the method implemented in the NetworkX package. This method is based on the “blossom” method for finding augmenting paths and the “primal-dual” method for finding a matching of maximum weight, you can read more about it there : https://dl.acm.org/citation.cfm?id=6502 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "#create the nodes\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(pa['PAID'][pa.UN == 0])\n",
    "G.add_nodes_from(pa['PAID'][pa.UN == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bipartite complete graph\n",
    "for ID_u, score_u in zip(pa.PAID[pa.UN == 0], pa.pred[pa.UN == 0]):\n",
    "    for ID_v, score_v in zip(pa.PAID[pa.UN == 1], pa.pred[pa.UN == 1]):\n",
    "        G.add_edge(ID_u, ID_v, weight=-abs(score_u-score_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check if the number of nodes and edges is right\n",
    "#Number of nodes should be 185+429 = 614 (the graph is bipartite) and number of edges should be 185*429 = 79365\n",
    "#because it is complete bipartite\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform the matching\n",
    "from networkx.algorithms import max_weight_matching\n",
    "matching = max_weight_matching(G, maxcardinality=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 68 PAIDs that need to be matched, here we notice the dictionnary goes in both ways\n",
    "len(list(matching.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_UN = pa[pa['UN'] == 1]\n",
    "pa_UN['temp'] = 1\n",
    "pa_UN = pa_UN[['PAID' , 'pred' , 'temp']]\n",
    "pa_nUN = pa[pa['UN'] == 0]\n",
    "pa_nUN['temp'] = 1\n",
    "pa_nUN = pa_nUN[['PAID' , 'pred' , 'temp']]\n",
    "\n",
    "\n",
    "#We merge the two datasets thanks to the temp column, this new merged dataset mimics the complete bipartite graph:\n",
    "result = pd.merge(pa_nUN ,pa_UN , on='temp', how='left')\n",
    "result = result[['PAID_x' , 'PAID_y' , 'pred_x' , 'pred_y']]\n",
    "result['diff'] = abs(result['pred_x'] - result['pred_y'])\n",
    "result = result.set_index(['PAID_x', 'PAID_y'])\n",
    "result['diff'].isnull().values.any()\n",
    "#result\n",
    "print(result.loc[list(matching.items())].dropna().shape)\n",
    "result.loc[list(matching.items())].dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paID = pa.set_index('PAID')\n",
    "matched = paID.loc[list(matching.keys())]\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='UN', data= matched, hue='ended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UN agreements are more 'ended' (so the conflicts start again) than the one without the UN intervention.\n",
    "But note that this analysis is still biased! \n",
    "Indeed, we only looked at the peace agreements here, we also need to look at the conflicts from these peace agreements. Maybe the UN only solved very difficult conflicts.\n",
    "In a second part we will look at the conflict that were solved and do another matching among them so we can redo this analysis with a filter on the conflict (will be done for markdown 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1287b16a-539a-41d2-a7ce-2e9173952f77"
    }
   },
   "source": [
    "# Conflicts\n",
    "\n",
    "## Cleaning the data\n",
    "\n",
    "As we studied in the previous part, we will need to balance our study over the conflict that has be solved by the UN vs the others.\n",
    "\n",
    "Indeed, the previous dataset only gave us informations about the peace agreement per se, we did not have any information about the conflict itself.\n",
    "\n",
    "UCDP has another data set that describes the conflicts. It is named *ucdp-prio-acd*.\n",
    "\n",
    "It is a conflict-year dataset with information on armed conflict where at least one party is the government of a state in the time period 1946-2016.\n",
    "\n",
    "The Conflict IDs are not the same between *ucdp-peace-agreements* and *ucdp-prio-acd* because UCDP changed the way the give IDs. The dataset *ucdp-peace-agreements* uses the old ID notation while *ucdp-prio-acd* uses the new one . Therefore, we need the translation give bt UCDP, *translate_conf*, to link them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the Peace Agreement dataset and the translation table to get the new IDs\n",
    "pa = pd.read_excel('data/ucdp-peace-agreements.xls')\n",
    "searchfor = ['UN', 'United Nations' , 'united nations' , 'ONU']\n",
    "pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('|'.join(searchfor))]\n",
    "inter = list(set(pa_UN.PAID).intersection(pa.PAID))\n",
    "pa[\"UN\"] = [1 if ele in inter else 0 for ele in pa.PAID]\n",
    "pa[pa['UN'] == 1]\n",
    "\n",
    "reader = csv.reader(open('data/translate_conf.csv', 'r'))\n",
    "\n",
    "#Create a dictionnary that will have {New ID : Old ID} so we can make the link\n",
    "d = {}\n",
    "for row in reader:\n",
    "    k, v = row\n",
    "    d[v] = k\n",
    "    \n",
    "#pa.CID = pa.CID.astype(dtype=str).replace(to_replace=d )\n",
    "pa.CID = pa.CID.astype(str)\n",
    "#print(type(pa.CID))\n",
    "pa.CID = pa.CID.apply(lambda x: d[x])\n",
    "pa.CID = pa.CID.astype(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6715c6a3-3737-48f5-9a5a-c805fd90acf5"
    }
   },
   "outputs": [],
   "source": [
    "#Import the conflict dataset\n",
    "df = pd.read_csv('data/ucdp-prio-acd-171.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b6db2428-2b7c-494c-a3c7-cde30c4f0d88"
    }
   },
   "outputs": [],
   "source": [
    "#Let's observe the data\n",
    "df.iloc[:10, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "75a97eeb-6cd5-416b-886b-1af5c71329e5"
    }
   },
   "outputs": [],
   "source": [
    "#Lot's of features so we do that in two times\n",
    "df.iloc[:10, 11:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice, there is several rows for the same conflict ID. Indeed, Each conflict is listed in the database and given a unique ID code. The temporal aspect of a conflict is not addressed by this definition; hence, two conflict episodes over the same incompatibility will be assigned the same ID regardless of the time separating them.\n",
    "\n",
    "This is how UCDP records the data, as explained on their website:\n",
    "\n",
    "- The observation (or unit) in the table is the conflict-year. Each conflict is listed in all years where fighting in one or more dyad(s) caused at least 25 battle-related deaths. The calendar year is the basic unit of every observation. Thus, if a conflict during the period June–September results in 30 casualties, that year will be recorded as a year of conflict. However, if the same number of casualties occurred in the period November–February and the conflict failed to reach the threshold of 25 battle-related deaths in either calendar year, neither year will be coded as in conflict. Start dates frequently refer to years prior to the first calendar year of a conflict, as the start of a conflict might be in a year with less than 25 fatalities. Small conflicts might not be included.\n",
    "\n",
    "Taking this into account, we decide to refine this dataset in order to have a single conflict ID per row. In order to do that we will aggregate the dataset at the CID (Conflict ID) level. To do so we will drop some variables that only concern the years of observation and not the conflict in its totality. This variables are :\n",
    "\n",
    "- `year` : The year of observation, which is not needed anymore as we will observe the conflict in its totality\n",
    "\n",
    "- `intensity` : The intensity of the conflict in a given year.\n",
    "\n",
    "- `startdate2` : The starting date of the observation (for a given year then, not the conflict itself).\n",
    "\n",
    "- `startprec2` : The precision of the `startdate2` variable.\n",
    "\n",
    "- `epend` : The ending date of the observation (same as above).\n",
    "\n",
    "- `ependprec` : The precision of the `epend` variable.\n",
    "\n",
    "These are the variables we droppend because we aggregate the dataset. We will drop some other variables because they are not needed in our analysis :\n",
    "\n",
    "- `sidea2nd` : If there is a secondary actor in the conflict on side A, we don't think we need that much precision.\n",
    "\n",
    "- `sideb2nd` : If there is a secondary actor in the conflict on side B, we don't think we need that much precision.\n",
    "\n",
    "- `terr` : The disputed territory if there is any. We don't need that much precision for a propensity score.\n",
    "\n",
    "- `startprec` : The precision of the starting date for the conflict. This is useless for our propensity score.\n",
    "\n",
    "- `gwnoa`, `gwnoa2nd`, `gwnob`, `gwnob2nd`, `gwnoloc` : This is only country codes etc, we don't need that for a propensity score.\n",
    "\n",
    "- `version` : The version of the dataset.\n",
    "\n",
    "We will describe the variables we keep in the next markdown, after we show the clean data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b9ffc367-7392-4282-88f6-9a6263a91326"
    }
   },
   "outputs": [],
   "source": [
    "#Let's remove the features we don't need for our analysis\n",
    "df.drop(['sidea2nd', 'sideb2nd' , 'terr' , 'year' , 'intensity' , 'startprec' , 'startdate2' , 'epend' , 'ependprec', 'gwnoa', 'gwnoa2nd', 'gwnob', 'gwnob2nd', 'gwnoloc', 'startprec2', 'version', 'sidebid'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "80490558-f2b0-414f-b9b0-458b7d754883"
    }
   },
   "outputs": [],
   "source": [
    "#Check how many conflicts we have\n",
    "print('Number of unique conflicts in this dataset : %s' %(len(df.conflictid.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of non-unique locations for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['location'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique 'side a' for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['sidea'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique 'side b' for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['side b'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique incomp for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['incomp'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique cumint for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['cumint'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique types for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['type'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique startdates for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['startdate'].unique().apply(len) > 1)]))\n",
    "print(\"Number of non-unique regions for a single conflict: %d\" %len(df['conflictid'].unique()[(df.groupby(df['conflictid'])['region'].unique().apply(len) > 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "dafa55eb-66fb-4838-874e-5481ad5df48a"
    }
   },
   "outputs": [],
   "source": [
    "#Let's aggregate the data to single CIDs (explanations in the markdown below)\n",
    "clean_df = df.groupby('conflictid').last()\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will explain the variables we retained and how we aggregated them:\n",
    "\n",
    "- `location` : The location of the conflict, this is always the same for each conflict ID, therefore we just take the value of the last observation for the aggregated dataset.\n",
    "\n",
    "- `sidea` : The first agent in the conflict (it has to be a government), this is always the same for each conflict ID, therefore we just take the value of the last observation for the aggregated dataset.\n",
    "\n",
    "- `side b` : The seconf agent in the conflict (it can be a government or an organisation), this is not always the same but after organisation we noticed that it was due to the organisation often changing name. Therefore we use the name of the organisation in the last observation for the aggregated dataset.\n",
    "\n",
    "- `incomp` : The incompatibility that led to the conflict. this is always the same for each CID, therefore we simply take the value of the last observation. Here are the three possible values :\n",
    "    - 1 : Territory\n",
    "    - 2 : Government\n",
    "    - 3 : Both\n",
    "    \n",
    "- `cumint` : It is a variable that says if the conflict did more than 1000 battle related deaths since its begining. Of course it is not the same accross the same CID because it is a cumulative variable, therefore we take the value for the last observation.\n",
    "\n",
    "- `Type` : The type of conflict. The type can change for the same CID. Though, we think that the most important is what the conflict was at its end (we have the `incomp` variable to tell us how the conflict began). Therefore, we take the last value for the aggregated dataset. There are four types of conflicts :\n",
    "    - 1 : Extrasystemic armed conflict occurs between a state and a non-state group outside its own territory.\n",
    "    - 2 : Interstate armed conflict occurs between two or more states. \n",
    "    - 3 : Internal armed conflict occurs between the government of a state and one or more internal opposition group(s) without intervention from other states.\n",
    "    - 4 : Internationalized internal armed conflict occurs between the government of a state and one or more internal opposition group(s) with intervention from other states (secondary parties) on one or both sides.\n",
    "    \n",
    "- `startdate` : The date of the start of the conflict, it is the same across all raws for the same CID so we can take whatever line when we aggregate.\n",
    "\n",
    "- `ependdate` : The end date of the episode observed. If this is the last episode it is the date of the end of the conflict for the CID. We take the date of the last observation when we aggregate then.\n",
    "\n",
    "- `region` : The region of the conflict, it is always the same across the same CID. Then we take the one for the last observation. The 5 regions are : \n",
    "    - 1 : Europe\n",
    "    - 2 : Middle East\n",
    "    - 3 : Asia\n",
    "    - 4 : Africa\n",
    "    - 5 : America\n",
    "    \n",
    "    \n",
    "Now we will use the other dataset in order to know if there was a Peace Agreement for this conflict. We will add a 0/1 column to capture this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3e2c4593-c8e6-41b4-b94b-89cd751ec103"
    }
   },
   "outputs": [],
   "source": [
    "#Check the CIDs that were ended by a peace agreement\n",
    "agreements = pa.groupby('CID').last()\n",
    "print('Number of unique conflicts that had a peace agreement : %s' %(len(agreements.index)))\n",
    "print(agreements.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check the CIDs that were ended by a peace agreement\n",
    "UN_agreements = pa[pa['UN']==1].groupby('CID').last()\n",
    "Other_agreements = pa[pa['UN']==0].groupby('CID').last()\n",
    "print('Number of unique conflicts that had a UN peace agreement : %s' %(len(UN_agreements.index)))\n",
    "print('Number of unique conflicts that had a peace agreement that did not involve the UN: %s' %(len(Other_agreements.index)))\n",
    "#print(agreements.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3fae2ee3-f5e1-4323-adbe-f5c13a91ccb4"
    }
   },
   "outputs": [],
   "source": [
    "#We add a column so we know if the CID had a peace agreement (1) or not (0)\n",
    "clean_df[\"agreement\"] = [1 if ele in agreements.index else 0 for ele in clean_df.index]\n",
    "clean_df[\"UN_agreement\"] = [1 if ele in UN_agreements.index else 0 for ele in clean_df.index]\n",
    "clean_df[\"Other_agreement\"] = [1 if ele in Other_agreements.index else 0 for ele in clean_df.index]\n",
    "clean_df.rename({'ependdate':'enddate'} , inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Date time so we can substract and have the duration\n",
    "clean_df['startdate'] = pd.to_datetime(clean_df['startdate'])\n",
    "clean_df['enddate'] = pd.to_datetime(clean_df['enddate'])\n",
    "clean_df['duration'] = (clean_df['enddate'] - clean_df['startdate']).dt.days\n",
    "clean_df['duration'].fillna(0 , inplace = True)\n",
    "\n",
    "\n",
    "#Categorical\n",
    "\n",
    "to_be_categorical = ['incomp' , 'cumint' , 'type' ,'region' , 'agreement' , 'UN_agreement' , 'Other_agreement']\n",
    "for categ in to_be_categorical:\n",
    "    clean_df[categ] = pd.Categorical(clean_df[categ] , clean_df[categ].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "74149268-6af8-4793-b064-06517520435d"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We now have a clean dataset\n",
    "clean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check that we have all the CIDs for peace agreement\n",
    "clean_df[clean_df['UN_agreement'] == 1].index\n",
    "pa_UN_CID = pa.loc[pa['CID'].isin(clean_df[clean_df['UN_agreement'] == 1].index)]\n",
    "pa_UN_CID['CID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('PA_Cleaned.csv' ,  pa_UN_CID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_UN_CID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='UN', data= pa_UN_CID, hue='ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='UN', data= pa, hue='ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.groupby(['UN' , 'ended']).count()\n",
    "# UN : 33% ended\n",
    "#Not UN : 36% ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_UN_CID.groupby(['UN' , 'ended']).count()\n",
    "#UN : 33% ended\n",
    "#Not UN : 42% ended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "In this section, we will observe the distributions for the conflict over the `agreement` variable as we will want to have a propensity score matching for the conflicts that did or did not receive a peace agreement. (And later for conflicts that did or did not receive a peace aggreement from the UN).\n",
    "\n",
    "We don't have any problems of missing values in this dataset, the only that we encounterd are for `enddate` and it simply means that the conflict is ongoing.\n",
    "\n",
    "The correlations we are interrested in are the ones of the different features with the `agreement` variable. These will be checked when we will plot the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "bb5b3bc3-9ed5-46bf-b4c7-1414df48ae66"
    }
   },
   "outputs": [],
   "source": [
    "#A function to have nice plots\n",
    "def plot_distrib(s1, s2, title, xLabel, yLabel, ax=None):\n",
    "    bins = np.histogram(s1)[1]\n",
    "    sns.distplot(s1, kde=False, color=COLOR_NO_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    sns.distplot(s2, kde=False, color=COLOR_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    if ax is None:\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xLabel)\n",
    "        plt.ylabel(yLabel)\n",
    "        plt.legend(['No agreement', 'Agreement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4b2db255-2b1e-4afc-a299-b14f1ef6c56a"
    }
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=clean_df['incomp'][clean_df['agreement'] == 0], s2=clean_df['incomp'][clean_df['agreement'] == 1], title='incomp', xLabel = 'incomp', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "from scipy import stats \n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'incomp'\n",
    "ks = stats.ks_2samp(clean_df['incomp'][clean_df['agreement'] == 0], clean_df['incomp'][clean_df['agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `incomp` distribution\n",
    "\n",
    "A Kolmogorov–Smirnov 2 sample test will help us be sure of our analysis.\n",
    "The Kolmogorov–Smirnov 2 sample test tests whether 2 samples are drawn from the same distribution. If the K-S statistic is small or the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same.\n",
    "\n",
    "The `incomp` variable seems to be equally distributed across the `agreement` variable. Indeed, the plot and the Kolmogorov-Smirnov 2-sample tests both tell us that we can't reject the null hypothesis as the p-value is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1addc7c6-b6b1-4948-834f-750eed2c4644"
    }
   },
   "outputs": [],
   "source": [
    "#plot the distrib\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=clean_df['cumint'][clean_df['agreement'] == 0], s2=clean_df['cumint'][clean_df['agreement'] == 1], title='cumint', xLabel = 'cumint', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'cumint'\n",
    "ks = stats.ks_2samp(clean_df['cumint'][clean_df['agreement'] == 0], clean_df['cumint'][clean_df['agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cumint` distribution\n",
    "\n",
    "Again the distributions are almost the same as seen on the plot. Furthermore, the p-value for the KS 2 sample test is very high (0.965) so we can't reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "efffb8a1-fcc6-4aa6-9a30-542044d4801e"
    }
   },
   "outputs": [],
   "source": [
    "#plot the distrib\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=clean_df['type'][clean_df['agreement'] == 0], s2=clean_df['type'][clean_df['agreement'] == 1], title='type', xLabel = 'type', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'type'\n",
    "ks = stats.ks_2samp(clean_df['type'][clean_df['agreement'] == 0], clean_df['type'][clean_df['agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `type` distribution\n",
    "\n",
    "Here the distrib look a bit different on the plot but the p-value for the KS 2 sample test tells us that we can't reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Date time so we can substract and have the duration\n",
    "clean_df['startdate'] = pd.to_datetime(clean_df['startdate'])\n",
    "clean_df['enddate'] = pd.to_datetime(clean_df['enddate'])\n",
    "clean_df['duration'] = (clean_df['enddate'] - clean_df['startdate']).dt.days\n",
    "clean_df['duration'].fillna(0 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the distrib\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=clean_df['duration'][clean_df['agreement'] == 0], s2=clean_df['duration'][clean_df['agreement'] == 1], title='duration', xLabel = 'duration', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'duration'\n",
    "ks = stats.ks_2samp(clean_df['duration'][clean_df['agreement'] == 0], clean_df['duration'][clean_df['agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `duration` distribution\n",
    "\n",
    "As we have the date, we can know the duration of the conflict by substracting the `enddate` and the `startdate`. The duration is given in days. \n",
    "\n",
    "The distribution kind of look the same across the conflicts that did or did not receive a peace agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6b8afecc-5146-4c24-a722-8fc7dac5e4f5"
    }
   },
   "outputs": [],
   "source": [
    "#Here we have to do the histogram ourselves\n",
    "locationNAcount = clean_df[clean_df['agreement'] == 0].groupby('location').count()['sidea']\n",
    "#Check the % for each location\n",
    "locationNAcount = locationNAcount / len(clean_df[clean_df['agreement'] == 0])\n",
    "locationNAcount.sort_values(ascending = False , inplace = True)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Distribution of locations for conflicts without an agreement')\n",
    "locationNAcount[:20].plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "be44c8fe-8f8d-4abd-849e-c29a1fd704cf"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "locationcount = clean_df[clean_df['agreement'] == 1].groupby('location').count()['sidea']\n",
    "#Check the % for each location\n",
    "locationcount = locationcount / len(clean_df[clean_df['agreement'] == 1])\n",
    "locationcount.sort_values(ascending = False , inplace = True)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Distribution of locations for conflicts with an agreement')\n",
    "locationcount[:20].plot('bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `location` distribution\n",
    "\n",
    "For the `location` variable the distribution looks quite different. On the other hand, this information is so different for every CID that it will be hard to use in our propensity score matching. We will prefer to check the distribution across the regions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regionNAcount = clean_df[clean_df['agreement'] == 0].groupby('region').count()['sidea']\n",
    "#Check the % for each region\n",
    "regionNAcount = regionNAcount / len(clean_df[clean_df['agreement'] == 0])\n",
    "regionNAcount.sort_values(ascending = False , inplace = True)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Distribution of regions for conflicts without an agreement')\n",
    "regionNAcount[:5].plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regioncount = clean_df[clean_df['agreement'] == 1].groupby('region').count()['sidea']\n",
    "#Check the % for each region\n",
    "regioncount = regioncount / len(clean_df[clean_df['agreement'] == 1])\n",
    "regioncount.sort_values(ascending = False , inplace = True)\n",
    "plt.figure(figsize=(12,5))\n",
    "regioncount.plot('bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `region` distribution\n",
    "\n",
    "For the `region` variable the distribution looks very different. This will have to be investigated and we will maybe force this variable to be equal in our propensity score matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link with the desegregated DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedf = pd.read_csv('data/ged171.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedf.head(20)\n",
    "#precisedf[precisedf['conflict_new_id'] == 205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedf[precisedf['country']=='France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of unique conflicts in this dataset : %s' %(len(precisedf.conflict_new_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtereddf = precisedf.loc[precisedf['conflict_new_id'].isin(clean_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of unique conflicts in this dataset : %s' %(len(filtereddf.conflict_new_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregatedf = filtereddf.groupby('conflict_new_id').sum()\n",
    "aggregatedf['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedf = precisedf[['conflict_new_id' , 'conflict_name' , 'best']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedfagg = precisedf.groupby('conflict_new_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisedfagg.merge(right = clean_df, how = 'outer' ,  left_index= True , right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df = clean_df.merge(right = precisedfagg , how = 'left' ,  left_index= True , right_index = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deadliest conflict\n",
    "clean_df['best'].fillna(0 , inplace = True)\n",
    "clean_df.sort_values(by = 'best' ,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity score matching between conflicts (UN as treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "#removing the useless features\n",
    "ag = clean_df[clean_df['agreement'] == 1]\n",
    "reg = ag[['incomp' , 'cumint' , 'type' , 'region' , 'duration']]\n",
    "#prepocess by standardizing the dataset\n",
    "reg = preprocessing.scale(reg)\n",
    "#Perform a logistic regression in order to get the propensity score for each individuals\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(reg, ag.UN_agreement)\n",
    "pred = model.predict_proba(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check the performance of the model\n",
    "sum(model.predict(reg) == ag.UN_agreement)/len(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag['CID'] = ag.index\n",
    "ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scatter plot of the propensity score\n",
    "plt.figure(figsize=(15, 10))\n",
    "ag['pred'] = pred[:,1]\n",
    "ax = sns.stripplot(x='CID', y='pred', hue='UN_agreement', data=ag, palette={0:\"#e74c3c\", 1: \"#2ecc71\"})\n",
    "ax.set(xticklabels=[], ylabel='Treatment (prediction)')\n",
    "plt.title('Propensity score per agreement')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., handles=ax.get_legend_handles_labels()[0], labels=['Without', 'With'], title='UN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "#create the nodes\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(ag['CID'][ag.UN_agreement == 0])\n",
    "G.add_nodes_from(ag['CID'][ag.UN_agreement == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bipartite complete graph\n",
    "for ID_u, score_u in zip(ag.CID[ag.UN_agreement == 0], ag.pred[ag.UN_agreement == 0]):\n",
    "    for ID_v, score_v in zip(ag.CID[ag.UN_agreement == 1], ag.pred[ag.UN_agreement == 1]):\n",
    "        G.add_edge(ID_u, ID_v, weight=-abs(score_u-score_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform the matching\n",
    "from networkx.algorithms import max_weight_matching\n",
    "matching = max_weight_matching(G, maxcardinality=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We have 68 PAIDs that need to be matched, here we notice the dictionnary goes in both ways\n",
    "len(list(matching.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag_UN = ag[ag['UN_agreement'] == 1]\n",
    "ag_UN['temp'] = 1\n",
    "ag_UN = ag_UN[['CID' , 'pred' , 'temp']]\n",
    "ag_nUN = ag[ag['UN_agreement'] == 0]\n",
    "ag_nUN['temp'] = 1\n",
    "ag_nUN = ag_nUN[['CID' , 'pred' , 'temp']]\n",
    "\n",
    "\n",
    "#We merge the two datasets thanks to the temp column, this new merged dataset mimics the complete bipartite graph:\n",
    "result = pd.merge(ag_nUN ,ag_UN , on='temp', how='left')\n",
    "result = result[['CID_x' , 'CID_y' , 'pred_x' , 'pred_y']]\n",
    "result['diff'] = abs(result['pred_x'] - result['pred_y'])\n",
    "result = result.set_index(['CID_x', 'CID_y'])\n",
    "result['diff'].isnull().values.any()\n",
    "#result\n",
    "print(result.loc[list(matching.items())].dropna().shape)\n",
    "matched_CIDs = result.loc[list(matching.items())].dropna()\n",
    "matched_CIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched_CIDs.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A function to have nice plots\n",
    "def plot_distrib(s1, s2, title, xLabel, yLabel, ax=None):\n",
    "    bins = np.histogram(s1)[1]\n",
    "    sns.distplot(s1, kde=False, color=COLOR_NO_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    sns.distplot(s2, kde=False, color=COLOR_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    if ax is None:\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xLabel)\n",
    "        plt.ylabel(yLabel)\n",
    "        plt.legend(['UN agreement', 'Other Agreement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['incomp'][ag['UN_agreement'] == 1], s2=ag['incomp'][ag['Other_agreement'] == 1], title='incomp', xLabel = 'incomp', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "from scipy import stats \n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'incomp'\n",
    "ks = stats.ks_2samp(ag['incomp'][ag['UN_agreement'] == 1], ag['incomp'][ag['Other_agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the cumint variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['cumint'][clean_df['UN_agreement'] == 1], s2=ag['cumint'][clean_df['Other_agreement'] == 1], title='cumint', xLabel = 'cumint', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'incomp'\n",
    "ks = stats.ks_2samp(clean_df['cumint'][clean_df['UN_agreement'] == 1], clean_df['cumint'][clean_df['Other_agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the type variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['type'][clean_df['UN_agreement'] == 1], s2=ag['type'][clean_df['Other_agreement'] == 1], title='type', xLabel = 'type', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'incomp'\n",
    "ks = stats.ks_2samp(clean_df['type'][clean_df['UN_agreement'] == 1], clean_df['type'][clean_df['Other_agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the type variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['duration'][clean_df['UN_agreement'] == 1], s2=ag['duration'][clean_df['Other_agreement'] == 1], title='duration', xLabel = 'duration', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KS 2 sample test to check distrib\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'incomp'\n",
    "ks = stats.ks_2samp(clean_df['duration'][clean_df['UN_agreement'] == 1], clean_df['duration'][clean_df['Other_agreement'] == 1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A function to have nice plots\n",
    "def plot_distrib(s1, s2, title, xLabel, yLabel, ax=None):\n",
    "    bins = np.histogram(s1)[1]\n",
    "    sns.distplot(s1, kde=False, color=COLOR_NO_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    sns.distplot(s2, kde=False, color=COLOR_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    if ax is None:\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xLabel)\n",
    "        plt.ylabel(yLabel)\n",
    "        plt.legend(['Conflict solved by another entity than the UN', 'Conflict solved by the UN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['incomp'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], s2=ag['incomp'][ag['UN_agreement']==1], title='incomp', xLabel = 'incomp', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'incomp'\n",
    "ks = stats.ks_2samp(ag['incomp'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], ag['incomp'][ag['UN_agreement']==1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['type'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], s2=ag['type'][ag['UN_agreement']==1], title='type', xLabel = 'type', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'type'\n",
    "ks = stats.ks_2samp(ag['type'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], ag['type'][ag['UN_agreement']==1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['cumint'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], s2=ag['cumint'][ag['UN_agreement']==1], title='cumint', xLabel = 'cumint', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'cumint'\n",
    "ks = stats.ks_2samp(ag['cumint'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], ag['cumint'][ag['UN_agreement']==1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['region'][ag['Other_agreement'] == 1][ag['UN_agreement']==0].astype(int), s2=ag['region'][ag['UN_agreement']==1].astype(int), title='region', xLabel = 'region', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'region'\n",
    "ks = stats.ks_2samp(ag['region'][ag['Other_agreement'] == 1][ag['UN_agreement']==0].astype(int), ag['region'][ag['UN_agreement']==1].astype(int)) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distrib for the incomp variable\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=ag['duration'][ag['Other_agreement'] == 1][ag['UN_agreement']==0].astype(int), s2=ag['duration'][ag['UN_agreement']==1].astype(int), title='region', xLabel = 'region', yLabel='Density', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n') \n",
    "feature = 'duration'\n",
    "ks = stats.ks_2samp(ag['duration'][ag['Other_agreement'] == 1][ag['UN_agreement']==0], ag['duration'][ag['UN_agreement']==1]) \n",
    "print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa = pd.read_excel('data/ucdp-peace-agreements.xls')\n",
    "searchfor = ['UN', 'United Nations' , 'united nations' , 'ONU']\n",
    "pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('|'.join(searchfor))]\n",
    "inter = list(set(pa_UN.PAID).intersection(pa.PAID))\n",
    "pa[\"UN\"] = [1 if ele in inter else 0 for ele in pa.PAID]\n",
    "pa[pa['UN'] == 1]\n",
    "\n",
    "reader = csv.reader(open('data/translate_conf.csv', 'r'))\n",
    "\n",
    "#Create a dictionnary that will have {New ID : Old ID} so we can make the link\n",
    "d = {}\n",
    "for row in reader:\n",
    "    k, v = row\n",
    "    d[v] = k\n",
    "    \n",
    "pa.CID = pa.CID.astype(str)\n",
    "pa.CID = pa.CID.apply(lambda x: d[x])\n",
    "pa.CID = pa.CID.astype(dtype = int)\n",
    "pa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inter = list(set(pa.CID).intersection(matched_CIDs.index.levels[1]))\n",
    "pa[\"matched\"] = [1 if ele in inter else 0 for ele in pa.CID]\n",
    "pa[pa['matched'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the .replace issue (SOLVED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the Peace Agreement dataset and the translation table to get the new IDs\n",
    "pa = pd.read_excel('data/ucdp-peace-agreements.xls')\n",
    "searchfor = ['UN', 'United Nations' , 'united nations' , 'ONU']\n",
    "pa_UN = pa[pa['pa_3rd'].astype(str).str.contains('|'.join(searchfor))]\n",
    "inter = list(set(pa_UN.PAID).intersection(pa.PAID))\n",
    "pa[\"UN\"] = [1 if ele in inter else 0 for ele in pa.PAID]\n",
    "pa[pa['UN'] == 1]\n",
    "\n",
    "reader = csv.reader(open('data/translate_conf.csv', 'r'))\n",
    "\n",
    "#Create a dictionnary that will have {New ID : Old ID} so we can make the link\n",
    "d = {}\n",
    "\n",
    "for row in reader:\n",
    "    k, v = row\n",
    "    d[v] = k\n",
    "    \n",
    "pa.CID = pa.CID.astype(str)\n",
    "#print(type(pa.CID))\n",
    "pa.CID = pa.CID.apply(lambda x: d[x])\n",
    "#pa = pa.replace(to_replace = d , )\n",
    "#pa.CID = pa.CID.astype(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ucdp-prio-acd-171.csv')\n",
    "df.drop(['sidea2nd', 'sideb2nd' , 'terr' , 'year' , 'intensity' , 'startprec' , 'startdate2' , 'epend' , 'ependprec', 'gwnoa', 'gwnoa2nd', 'gwnob', 'gwnob2nd', 'gwnoloc', 'startprec2', 'version', 'sidebid'], axis=1, inplace = True)\n",
    "clean_df = df.groupby('conflictid').last()\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pa[pa['PAID'] == 1001999050601]\n",
    "clean_df.loc[335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa = pd.read_excel('data/ucdp-peace-agreements.xls')\n",
    "pa[pa['PAID'] == 1001999050601]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the next markdown :\n",
    "\n",
    "## Propensity score matching agreements / no agreements :\n",
    "\n",
    "Even if the distributions across the variables looks quite the same, it will be interresting to check how a propensity score matching works on this data and then check if a peace agreement helps to bring stability in a region or not. We will have to code the later variable. We already have a few ideas on how to do that.\n",
    "\n",
    "## Propensity score matching agreements / UN agreements : \n",
    "\n",
    "Then we will run the same analysis as we previously did but this time we will filter the CIDs to be distributed the same before doing another propensity score matching on the agreements so we are sure our analysis is not naive.\n",
    "\n",
    "## Plot the map of the conflicts/ Peace Agreements\n",
    "\n",
    "### Attention je crois que des pays s'affichent en couleur alors que pas de conflit (Pb de cut de date je pense)\n",
    "\n",
    "### Est-ce qu'on met des couleurs à des endroits ou il n'y a pas de conflit ?(si oui je pense qu'on ne devrait pas)\n",
    "\n",
    "### Dès qu'on clique les couleurs apparaissent\n",
    "\n",
    "### Check le \"conflit de 2001 à 2016\" aux states, ca semble bizarre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df[clean_df['location'] == 'United States of America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ucdp-prio-acd-171.csv')\n",
    "df[][df['conflictid'] == 418]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map data cleaning\n",
    "The goal here is to clean the geographical data columns so that the countries' names match with the names in the geojson file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open('./data/countries.geo.json'))\n",
    "map_countries = set([country['properties']['name'] for country in data['features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes a string as input and returns the cleaned string\n",
    "def clean_location(location):\n",
    "    location = re.sub(r'\\([^)]*\\)', '', location)\n",
    "    location = re.sub(', ', ',', location)\n",
    "    location = re.sub(' ,', ',', location)\n",
    "    return location.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df.location = clean_df.location.apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's check how many countries from the data still have no matcing on the map\n",
    "def print_unmatched(map_countries):\n",
    "    data_countries = set(clean_df.location.values)\n",
    "    no_match = []\n",
    "    for entry in data_countries:\n",
    "        # some entries have several countries separated by a ','\n",
    "        for country in entry.split(','):\n",
    "            if country not in map_countries:\n",
    "                no_match.append(country)\n",
    "    print(\"There are \" + str(len(set(no_match))) + \" locations that are not on the map:\")\n",
    "    print(set(no_match))\n",
    "print_unmatched(map_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some manual corrections for the few locations that are still unmatched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manual_matchings = {\n",
    "    'Bosnia-Herzegovina' : 'Bosnia and Herzegovina',\n",
    "    'Tanzania' : 'United Republic of Tanzania',\n",
    "    'Comoros' : 'Madagascar',\n",
    "    'South Yemen' : 'Yemen',\n",
    "    'DR Congo' : 'Democratic Republic of the Congo',\n",
    "    'Hyderabad' : 'India',\n",
    "    'South Vietnam' : 'Vietnam',\n",
    "    'FYR' : 'Macedonia',\n",
    "    'Grenada' : 'Spain',\n",
    "    'Rumania' : 'Romania',\n",
    "    'Serbia' : 'Republic of Serbia',\n",
    "    'Congo' : 'Republic of the Congo',\n",
    "    'Guinea-Bissau' : 'Guinea Bissau',\n",
    "}\n",
    "def replace_names(location):\n",
    "    names = list(set([manual_matchings[x] if x in manual_matchings else x for x in location.split(',')]))\n",
    "    return ','.join(names)\n",
    "clean_df.location = clean_df.location.apply(replace_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_unmatched(map_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the locations' IDs from the GeoJson to the dataframe\n",
    "The GeoJSON contains for each location a unique ID. We add these locations to the dataframe to use them as unique identifiers in the front-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build location -> locID dictionnary\n",
    "loc_id_dict = dict()\n",
    "for country in data['features']:\n",
    "    loc_id_dict[country['properties']['name']] = country['id']\n",
    "    if country['id'] == '-99':\n",
    "        print(country['properties']['name'])\n",
    "        \n",
    "def getLocationIds(locations):\n",
    "    ids = []\n",
    "    for loc in locations.split(','):\n",
    "        ids.append(loc_id_dict[loc])\n",
    "    return ','.join(ids)\n",
    "        \n",
    "# Add locationID to the dataframe\n",
    "clean_df['locationID'] = clean_df.location.apply(getLocationIds)\n",
    "clean_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add location IDs to the dataframe\n",
    "#clean_df.head()\n",
    "#clean_df['locationID'] = clean_df.location.map(loc_id_dict)\n",
    "print(clean_df.location.unique().size)\n",
    "print(clean_df['locationID'].unique().size)\n",
    "#clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data as a csv file\n",
    "Now the data is clean, let's export it in a csv file to use it in the front-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df.to_csv('conflicts.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df[clean_df.location == 'Russia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df.enddate.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
